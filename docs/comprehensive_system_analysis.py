
import json
import os
import re
from collections import defaultdict

def load_json_data(filepath):
    with open(filepath, 'r') as f:
        return json.load(f)

def analyze_structure(data):
    tables = {} 
    
    for item in data:
        section = item.get('section')
        table = item.get('table_name')
        name = item.get('name')
        details_str = item.get('details')
        
        try:
            details = json.loads(details_str) if details_str else {}
        except:
            details = {"raw": details_str}

        if section == '02_TABLE_META':
            if table not in tables:
                tables[table] = {'description': '', 'columns': {}, 'details': details}
            # Merge details if already exists (rare case)
            elif not tables[table]['details']:
                 tables[table]['details'] = details
        
        elif section == '05_COLUMN':
            if table not in tables:
                # Should have been created by TABLE_META but just in case
                tables[table] = {'description': '', 'columns': {}, 'details': {}}
            tables[table]['columns'][name] = details

    return tables

def scan_codebase_smart(root_dirs, tables_info):
    """
    Scans codebase using a 'Co-occurrence' heuristic.
    A column is considered 'used' if it appears in a file that ALSO contains its table name.
    Unique column names (not in common_ignore) are also searched globally as a fallback.
    """
    
    table_usage = defaultdict(int)
    column_usage = defaultdict(int)
    
    common_cols = {'id', 'created_at', 'updated_at', 'user_id', 'uuid', 'metadata'}
    
    file_contents = []
    
    print("Loading file contents...")
    for root_dir in root_dirs:
        abs_root_dir = os.path.join(os.getcwd(), root_dir)
        if not os.path.exists(abs_root_dir):
            continue
            
        for root, dirs, files in os.walk(abs_root_dir):
            if 'node_modules' in dirs: dirs.remove('node_modules')
            if '.git' in dirs: dirs.remove('.git')
            
            for file in files:
                if not (file.endswith('.tsx') or file.endswith('.ts') or file.endswith('.js') or file.endswith('.jsx')):
                    continue
                    
                path = os.path.join(root, file)
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        file_contents.append(content)
                except:
                    pass
    
    print(f"Scanned {len(file_contents)} files. analyzing usage...")

    for table, info in tables_info.items():
        relevant_files = [] 
        
        for content in file_contents:
            if table in content:
                table_usage[table] += 1
                relevant_files.append(content)
        
        for col in info['columns']:
            found_in_context = False
            for content in relevant_files:
                if col in content:
                    column_usage[f"{table}.{col}"] += 1
                    found_in_context = True
            
            if not found_in_context and col not in common_cols:
                count_global = 0
                for content in file_contents:
                    if col in content:
                        count_global += 1
                
                if count_global > 0:
                     column_usage[f"{table}.{col}"] = count_global 

    return table_usage, column_usage

def generate_reports(tables, table_usage, column_usage):
    ui_report = []
    db_report = []

    # UI Report Header
    ui_report.append("# ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (UI Analysis Report)\n")
    ui_report.append("ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ¬ÙˆØ§Øª Ø¨ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙƒÙˆØ¯ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Frontend/Backend).\n")
    ui_report.append("**Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„**: ÙŠØªÙ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ØŒ Ø«Ù… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø¹Ù…Ø¯ØªÙ‡ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ Ø°ÙƒØ±Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ø³ÙŠØ§Ù‚ Ù…Ø±ØªØ¨Ø·)ØŒ Ø£Ùˆ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§ Ø¹Ø§Ù„Ù…ÙŠÙ‹Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ù…ÙŠØ²Ø©.\n")

    # DB Report Header
    db_report.append("# ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Database Analysis Report)\n")
    db_report.append("Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ Ù…Ù…Ù„ Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.\n")

    missing_high_priority = []

    for table, info in sorted(tables.items()):
        # -- DB Section --
        db_report.append(f"## Ø§Ù„Ø¬Ø¯ÙˆÙ„: `{table}`")
        if info['details']:
             comment = info['details'].get('description', '')
             if comment and comment != "No description":
                 db_report.append(f"**Ø§Ù„ÙˆØµÙ**: {comment}\n")
        
        db_report.append("| Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ | Ø§Ù„Ù†ÙˆØ¹ | Nullable | Default |")
        db_report.append("| :--- | :--- | :--- | :--- |")
        
        # -- UI Section --
        t_usage = table_usage.get(table, 0)
        is_table_used = t_usage > 0
        status_icon = "âœ…" if is_table_used else "âš ï¸"
        
        ui_report.append(f"## {status_icon} Ø§Ù„Ø¬Ø¯ÙˆÙ„: `{table}`")
        if not is_table_used:
            ui_report.append(f"> **ØªÙ†Ø¨ÙŠÙ‡**: Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù… ØµØ±Ø§Ø­Ø© ÙÙŠ Ø§Ù„ÙƒÙˆØ¯.\n")
        
        ui_report.append("| Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ | Ø§Ù„Ø­Ø§Ù„Ø© | Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ |")
        ui_report.append("| :--- | :--- | :--- |")

        for col, col_details in sorted(info['columns'].items()):
            # DB Details
            dtype = col_details.get('type', {}).get('data_type', 'N/A')
            nullable = col_details.get('nullable', 'N/A')
            default_val = col_details.get('default', '')
            db_report.append(f"| `{col}` | {dtype} | {nullable} | {default_val} |")

            # UI Details
            usage_key = f"{table}.{col}"
            count = column_usage.get(usage_key, 0)
            
            if count > 0:
                col_status = "âœ… Ù…Ø³ØªØ®Ø¯Ù…"
            else:
                if col in ['id', 'created_at', 'updated_at', 'metadata']:
                    col_status = "âš ï¸ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ (Ù†Ø¸Ø§Ù…)"
                else:
                    col_status = "ğŸ”´ **Ù…ÙÙ‚ÙˆØ¯**"
                    missing_high_priority.append(f"`{table}.{col}`")

            ui_report.append(f"| `{col}` | {col_status} | {count} |")
        
        db_report.append("\n")
        ui_report.append("\n")

    if missing_high_priority:
        ui_report.insert(3, "\n## ğŸš¨ Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (High Priority Gaps)\nÙ‡Ø°Ù‡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ„ÙƒÙ† Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµØ±ÙŠØ­ Ù„Ù‡Ø§ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯:\n" + "\n- ".join(missing_high_priority) + "\n\n---\n")

    # Save Reports
    with open('docs/REPORT_UI_GAPS.md', 'w', encoding='utf-8') as f:
        f.write('\n'.join(ui_report))
    
    with open('docs/REPORT_DB_STRUCTURE.md', 'w', encoding='utf-8') as f:
        f.write('\n'.join(db_report))
        
    print(f"Analysis Complete. Found {len(missing_high_priority)} potential gaps.")

def main():
    json_path = '/Volumes/alaaMac/Archive/qazzzzzzz/docs/database_xray_output.json'
    if not os.path.exists(json_path):
        print(f"JSON file not found at {json_path}")
        return

    data = load_json_data(json_path)
    tables = analyze_structure(data)
    
    table_usage, column_usage = scan_codebase_smart(['app', 'components', 'lib', 'utils', 'hooks'], tables)
    
    generate_reports(tables, table_usage, column_usage)

if __name__ == "__main__":
    main()
